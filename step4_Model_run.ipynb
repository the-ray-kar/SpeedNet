{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.load(\"../sp_data/Full_data/points.npy\")\n",
    "width  = 64\n",
    "height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(frame, points,width,height):\n",
    "        \n",
    "        assert len(points)==4,\"no of points not equal to 4\"\n",
    "\n",
    "        # Define the destination points for the perspective transform\n",
    "        \n",
    "        \n",
    "        dst_points = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "        # Convert points to numpy array format\n",
    "        src_points = np.float32(points)\n",
    "\n",
    "        # Compute the perspective transform matrix\n",
    "        Mat = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "        # Apply the perspective transform to the frame\n",
    "        warped_image = cv2.warpPerspective(frame, Mat, (width, height))\n",
    "\n",
    "        warped_image  =cv2.cvtColor(warped_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        return warped_image\n",
    "\n",
    "def process_input(old_frame,new_frame):\n",
    "        old = apply_perspective_transform(old_frame,points,width,height)\n",
    "        new = apply_perspective_transform(new_frame,points,width,height)\n",
    "        np_input = np.array([[old,new]]) #To create a tensor 1 x 2 x H x W\n",
    "        input_tensor =torch.tensor(np_input,dtype=torch.float32)/255 \n",
    "        return input_tensor,new\n",
    "\n",
    "def load_label_data():\n",
    "        labels = []\n",
    "        with open(\"../sp_data/train.txt\", 'r') as file:\n",
    "             for line in file:\n",
    "                line.replace(\"\\n\",\"\")\n",
    "                labels.append(float(line))\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpeedNet2(nn.Module):\n",
    "    def __init__(self, in_channels, f1,f2,f3,f4,f5):\n",
    "        super(SpeedNet2, self).__init__()\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm3d(f1)\n",
    "        self.batchnorm2 = nn.BatchNorm3d(f2)\n",
    "        self.batchnorm3 = nn.BatchNorm3d(f3)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(f4)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(f5)\n",
    "        # First 3D convolution layer\n",
    "        self.conv3d_1 = nn.Conv3d(in_channels, f1, kernel_size=(1, 5, 5))\n",
    "        self.pool3d_1 = nn.MaxPool3d(kernel_size=(1, 1, 3), stride=(1, 1, 2))\n",
    "        \n",
    "        # Second 3D convolution layer\n",
    "        self.conv3d_2 = nn.Conv3d(f1, f2, kernel_size=(1, 5, 5))\n",
    "        self.pool3d_2 = nn.MaxPool3d(kernel_size=(1, 1, 2), stride=(1, 1, 2))\n",
    "        \n",
    "        # Third 3D convolution layer\n",
    "        self.conv3d_3 = nn.Conv3d(f2, f3, kernel_size=(2, 5, 5))\n",
    "        \n",
    "        # 2D convolution layer\n",
    "        self.conv2d_1 = nn.Conv2d(f3, f4, kernel_size=(10, 7))\n",
    "        self.pool2d_1 = nn.MaxPool2d(kernel_size=(9, 1), stride=(9, 2))\n",
    "\n",
    "        self.conv2d_2 = nn.Conv2d(f4, f5, kernel_size=(5, 1))\n",
    "        self.pool2d_2 = nn.MaxPool2d(kernel_size=(5, 1), stride=(5, 1))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "    def deb_forward(self, x):\n",
    "        # Reshape input tensor to add the single channel dimension\n",
    "        print(\"Before unsqueeze:\", x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        print(\"After unsqueeze:\", x.shape)\n",
    "        \n",
    "        # First 3D convolution and pooling\n",
    "        x = self.conv3d_1(x)\n",
    "        print(\"After conv3d_1:\", x.shape)\n",
    "        x = self.pool3d_1(x)\n",
    "        print(\"After pool3d_1:\", x.shape)\n",
    "        \n",
    "        \n",
    "        # Second 3D convolution and pooling\n",
    "        x = self.conv3d_2(x)\n",
    "        print(\"After conv3d_2:\", x.shape)\n",
    "        x = self.pool3d_2(x)\n",
    "        print(\"After pool3d_2:\", x.shape)\n",
    "        \n",
    "        # Third 3D convolution\n",
    "        x = self.conv3d_3(x)\n",
    "        print(\"After conv3d_3:\", x.shape)\n",
    "        \n",
    "        # Squeeze the third dimension\n",
    "        x = x.squeeze(2)\n",
    "        print(\"After squeeze:\", x.shape)\n",
    "        \n",
    "        # First 2D convolution and pooling\n",
    "        x = self.conv2d_1(x)\n",
    "        print(\"After conv2d_1:\", x.shape)\n",
    "        x = self.pool2d_1(x)\n",
    "        print(\"After pool2d_1:\", x.shape)\n",
    "\n",
    "        # Second 2D convolution and pooling\n",
    "        x = self.conv2d_2(x)\n",
    "        print(\"After conv2d_2:\", x.shape)\n",
    "\n",
    "        x = self.pool2d_2(x)\n",
    "        print(\"After pool2d_2:\", x.shape)\n",
    "\n",
    "        \n",
    "        # Flatten the data\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(\"After flatten:\", x.shape)\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))fter conv2d_1: torch.Size([2, 128, 235, 2\n",
    "        # x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input tensor to add the single channel dimension\n",
    "        #print(\"Before unsqueeze:\", x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(\"After unsqueeze:\", x.shape)\n",
    "        \n",
    "        # First 3D convolution and pooling\n",
    "        x = self.conv3d_1(x)\n",
    "        #print(\"After conv3d_1:\", x.shape)\n",
    "        x = self.pool3d_1(x)\n",
    "        #print(\"After pool3d_1:\", x.shape)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        # Second 3D convolution and pooling\n",
    "        x = self.conv3d_2(x)\n",
    "        #print(\"After conv3d_2:\", x.shape)\n",
    "        x = self.pool3d_2(x)\n",
    "        #print(\"After pool3d_2:\", x.shape)\n",
    "        x = self.batchnorm2(x)\n",
    "        # Third 3D convolution\n",
    "        x = self.conv3d_3(x)\n",
    "        #print(\"After conv3d_3:\", x.shape)\n",
    "        x = self.batchnorm3(x)\n",
    "        # Squeeze the third dimension\n",
    "        x = x.squeeze(2)\n",
    "        #print(\"After squeeze:\", x.shape)\n",
    "        \n",
    "        # First 2D convolution and pooling\n",
    "        x = self.conv2d_1(x)\n",
    "        #print(\"After conv2d_1:\", x.shape)\n",
    "        x = self.pool2d_1(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        #print(\"After pool2d_1:\", x.shape)\n",
    "\n",
    "        # Second 2D convolution and pooling\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.pool2d_2(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        #print(\"After conv2d_2:\", x.shape)\n",
    "        \n",
    "        \n",
    "        # Flatten the data\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"After flatten:\", x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = SpeedNet2(1, 8,16,32,128,256)  # Increased features to 128 \n",
    "model.load_state_dict(torch.load(\"Models/SpeedNet_128.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_data = np.array(load_label_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frame is  20400\n"
     ]
    }
   ],
   "source": [
    "#cap.release()\n",
    "cap = cv2.VideoCapture(\"../sp_data/train.mp4\")\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Number of frame is \",frame_count)\n",
    "start_frame = 5000\n",
    "end_frame = 6500\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame) \n",
    "cv2.namedWindow(\"Result Calculated Speed\")\n",
    "cv2.namedWindow(\"What Neural Net Sees\")\n",
    "ret,old_frame = cap.read()\n",
    "count = start_frame\n",
    "old_speed = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    input_tensor,pers_transformed_image = process_input(old_frame,frame)\n",
    "    #print(input_tensor.shape)\n",
    "    speed_tensor = model.forward(input_tensor)\n",
    "    speed = (speed_tensor.item()+1)*max(speed_data)/2\n",
    "    speed = old_speed*0.95 + 0.05*speed\n",
    "    old_speed = speed*1\n",
    "    text = \"Calculated: \"+ str(round(speed,1))+\", Actual: \"+str(round(speed_data[count-1:count].mean(),1))+\",Frame \"+str(count)\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_COMPLEX, 0.7,1)\n",
    "    \n",
    "    margin = 10\n",
    "    box_width = text_width + 2 * margin\n",
    "    box_height = text_height + 2 * margin\n",
    "    box_top_left = (10, 40-box_height+margin)\n",
    "    box_bottom_right = (box_top_left[0] + box_width, box_top_left[1] + box_height)\n",
    "    cv2.rectangle(frame, box_top_left, box_bottom_right, (0, 0, 0), -1)\n",
    "    cv2.putText(frame,text, (20,40), cv2.FONT_HERSHEY_COMPLEX,0.7, (0,255,0),1)\n",
    "    cv2.imshow(\"Result Calculated Speed\",frame)\n",
    "    cv2.imshow(\"What Neural Net Sees\",pers_transformed_image)\n",
    "    \n",
    "    #print(\"Calculated :\",(speed_tensor.item()+1)*max(speed_data)/2,\"Actual : \",speed_data[count])\n",
    "    old_frame = frame.copy()\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q') or count>end_frame:\n",
    "            break\n",
    "    count+=1\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
