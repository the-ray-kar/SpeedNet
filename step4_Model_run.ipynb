{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.load(\"../sp_data/Full_data/points.npy\")\n",
    "width  = 64\n",
    "height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(frame, points,width,height):\n",
    "        \n",
    "        assert len(points)==4,\"no of points not equal to 4\"\n",
    "\n",
    "        # Define the destination points for the perspective transform\n",
    "        \n",
    "        \n",
    "        dst_points = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
    "\n",
    "        # Convert points to numpy array format\n",
    "        src_points = np.float32(points)\n",
    "\n",
    "        # Compute the perspective transform matrix\n",
    "        Mat = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "        # Apply the perspective transform to the frame\n",
    "        warped_image = cv2.warpPerspective(frame, Mat, (width, height))\n",
    "\n",
    "        warped_image  =cv2.cvtColor(warped_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        return warped_image\n",
    "\n",
    "def process_input(old_frame,new_frame):\n",
    "        old = apply_perspective_transform(old_frame,points,width,height)\n",
    "        new = apply_perspective_transform(new_frame,points,width,height)\n",
    "        np_input = np.array([[old,new]]) #To create a tensor 1 x 2 x H x W\n",
    "        input_tensor =torch.tensor(np_input,dtype=torch.float32)/255 \n",
    "        return input_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10199, 2, 256, 64) (10199,)\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "frame_data = np.load(\"../sp_data/Full_data/framedata.npy\",allow_pickle=True)\n",
    "labeldata = np.load(\"../sp_data/Full_data/meanlabels2.npy\",allow_pickle=True)\n",
    "frame_data = np.array(frame_data)\n",
    "print(frame_data.shape,labeldata.shape)\n",
    "frame_data_tensor = torch.tensor(frame_data,dtype=torch.float32)/255 #Create tensor and normalize\n",
    "labels_tensor = torch.tensor(2*labeldata/max(labeldata)-1, dtype=torch.float32) #create tensor and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpeedNet2(nn.Module):\n",
    "    def __init__(self, in_channels, f1,f2,f3,f4,f5):\n",
    "        super(SpeedNet2, self).__init__()\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm3d(f1)\n",
    "        self.batchnorm2 = nn.BatchNorm3d(f2)\n",
    "        self.batchnorm3 = nn.BatchNorm3d(f3)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(f4)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(f5)\n",
    "        # First 3D convolution layer\n",
    "        self.conv3d_1 = nn.Conv3d(in_channels, f1, kernel_size=(1, 5, 5))\n",
    "        self.pool3d_1 = nn.MaxPool3d(kernel_size=(1, 1, 3), stride=(1, 1, 2))\n",
    "        \n",
    "        # Second 3D convolution layer\n",
    "        self.conv3d_2 = nn.Conv3d(f1, f2, kernel_size=(1, 5, 5))\n",
    "        self.pool3d_2 = nn.MaxPool3d(kernel_size=(1, 1, 2), stride=(1, 1, 2))\n",
    "        \n",
    "        # Third 3D convolution layer\n",
    "        self.conv3d_3 = nn.Conv3d(f2, f3, kernel_size=(2, 5, 5))\n",
    "        \n",
    "        # 2D convolution layer\n",
    "        self.conv2d_1 = nn.Conv2d(f3, f4, kernel_size=(10, 7))\n",
    "        self.pool2d_1 = nn.MaxPool2d(kernel_size=(9, 1), stride=(9, 2))\n",
    "\n",
    "        self.conv2d_2 = nn.Conv2d(f4, f5, kernel_size=(5, 1))\n",
    "        self.pool2d_2 = nn.MaxPool2d(kernel_size=(5, 1), stride=(5, 1))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(1024, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32,1)\n",
    "        \n",
    "    def deb_forward(self, x):\n",
    "        # Reshape input tensor to add the single channel dimension\n",
    "        print(\"Before unsqueeze:\", x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        print(\"After unsqueeze:\", x.shape)\n",
    "        \n",
    "        # First 3D convolution and pooling\n",
    "        x = self.conv3d_1(x)\n",
    "        print(\"After conv3d_1:\", x.shape)\n",
    "        x = self.pool3d_1(x)\n",
    "        print(\"After pool3d_1:\", x.shape)\n",
    "        \n",
    "        \n",
    "        # Second 3D convolution and pooling\n",
    "        x = self.conv3d_2(x)\n",
    "        print(\"After conv3d_2:\", x.shape)\n",
    "        x = self.pool3d_2(x)\n",
    "        print(\"After pool3d_2:\", x.shape)\n",
    "        \n",
    "        # Third 3D convolution\n",
    "        x = self.conv3d_3(x)\n",
    "        print(\"After conv3d_3:\", x.shape)\n",
    "        \n",
    "        # Squeeze the third dimension\n",
    "        x = x.squeeze(2)\n",
    "        print(\"After squeeze:\", x.shape)\n",
    "        \n",
    "        # First 2D convolution and pooling\n",
    "        x = self.conv2d_1(x)\n",
    "        print(\"After conv2d_1:\", x.shape)\n",
    "        x = self.pool2d_1(x)\n",
    "        print(\"After pool2d_1:\", x.shape)\n",
    "\n",
    "        # Second 2D convolution and pooling\n",
    "        x = self.conv2d_2(x)\n",
    "        print(\"After conv2d_2:\", x.shape)\n",
    "\n",
    "        x = self.pool2d_2(x)\n",
    "        print(\"After pool2d_2:\", x.shape)\n",
    "\n",
    "        \n",
    "        # Flatten the data\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(\"After flatten:\", x.shape)\n",
    "\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))fter conv2d_1: torch.Size([2, 128, 235, 2\n",
    "        # x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input tensor to add the single channel dimension\n",
    "        #print(\"Before unsqueeze:\", x.shape)\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(\"After unsqueeze:\", x.shape)\n",
    "        \n",
    "        # First 3D convolution and pooling\n",
    "        x = self.conv3d_1(x)\n",
    "        #print(\"After conv3d_1:\", x.shape)\n",
    "        x = self.pool3d_1(x)\n",
    "        #print(\"After pool3d_1:\", x.shape)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        # Second 3D convolution and pooling\n",
    "        x = self.conv3d_2(x)\n",
    "        #print(\"After conv3d_2:\", x.shape)\n",
    "        x = self.pool3d_2(x)\n",
    "        #print(\"After pool3d_2:\", x.shape)\n",
    "        x = self.batchnorm2(x)\n",
    "        # Third 3D convolution\n",
    "        x = self.conv3d_3(x)\n",
    "        #print(\"After conv3d_3:\", x.shape)\n",
    "        x = self.batchnorm3(x)\n",
    "        # Squeeze the third dimension\n",
    "        x = x.squeeze(2)\n",
    "        #print(\"After squeeze:\", x.shape)\n",
    "        \n",
    "        # First 2D convolution and pooling\n",
    "        x = self.conv2d_1(x)\n",
    "        #print(\"After conv2d_1:\", x.shape)\n",
    "        x = self.pool2d_1(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        #print(\"After pool2d_1:\", x.shape)\n",
    "\n",
    "        # Second 2D convolution and pooling\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.pool2d_2(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        #print(\"After conv2d_2:\", x.shape)\n",
    "        \n",
    "        \n",
    "        # Flatten the data\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"After flatten:\", x.shape)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = SpeedNet2(1, 8,16,32,128,256)  # Increased features to 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'../sp_data/Full_data/SpeedNet_64_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
